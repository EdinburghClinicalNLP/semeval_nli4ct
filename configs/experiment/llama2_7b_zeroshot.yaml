# @package _global_
defaults:
  - override /model: llama2_7b
  - override /data: nli4ct
  - override /dataloader: language_modelling
  - override /lr_scheduler: warmup_linear_decay
  - override /optimizer: adamw


trainer:
  epochs: 20
  gradient_accumulation_steps: 64