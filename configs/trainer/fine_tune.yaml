defaults:
  - base_trainer_config

name: fine_tune
configs:
  epochs: 10
  gradient_accumulation_steps: 32
  lora_configs:
    r: 8
    lora_alpha: 16
    lora_dropout: 0.1
    target_modules: ["k_proj", "q_proj", "v_proj"]
